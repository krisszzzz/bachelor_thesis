\section{Заключение}
В данной дипломной работе была поставлена задача разработки высокопроизводительных библиотек машинного обучения cuBLAS и cuDNN,
предназначенных для выполнения матричного умножения, операций свёртки и пакетной нормализации. Основной целью работы стало создание
эффективных интерфейсов, которые могут быть использованы в нейронных сетях с фреймворком PyTorch, а также их тестирование на функциональном
и потактовом симуляторах, поддерживающих модель CUDA.

В процессе выполнения работы были решены ключевые задачи, включая разработку интерфейсов для основных операций, определение методологии тестирования
и оценка производительности разработанных библиотек. Проведённые исследования показали, что разработанные решения обеспечивают высокую производительность
и стабильность работы, соответствуя требованиям современных задач машинного обучения.

Разработана система тестирования, включающая функциональную проверку и оценку производительности на реальных устройствах NVIDIA Jetson и симуляторе gem5.
Проведено тестирование на широком спектре нейронных сетей (ResNet, EfficientNet, YOLOv11, UNET и др.), подтвердившее корректность работы библиотек в
реальных сценариях.

Разработаны оптимизированные версии операций \texttt{cublasLtMatmul}, \texttt{cudnnConvolutio\-nForward} и \texttt{cudnnBatchNormalizationForwardInference},
необходимые для запуска нейронных сетей, использующих фреймворк PyTorch. Для матричного умножения (\texttt{cublasL\-tMatmul}) реализован на базе библиотеки CUTLASS
и предложен алгоритм выбора оптимальных параметров, что позволило достичь 90 \% производительности эталонной реализации cuBLAS. Реализация пакетной нормализации
(\texttt{cudnnBatchNormalizationForwa\-rdInference}) продемонстрировала 99,7 \% производительности по сравнению с cuDNN для формата NCHW.
Операция свёртки (\texttt{cudnnConvolutionForward}) реализована для форматов NHWC и NCHW; для последнего дополнительно оптимизированы свёртки
с фильтром $1\times1$ как при единичном шаге свертки, так и при шаге, превышающем единицу. В результате оптимизаций достигнута производительность,
сопоставимая с cuDNN: 100\% для свертки $1\times1$ c шагом 1 и 85\% -- с шагом больше единицы.

Разработанные библиотеки cuBLAS и cuDNN обеспечивают высокую производительность, что делает их пригодными для использования в задачах машинного обучения на
GPGPU-ускорителях, поддерживающих модель CUDA. Результаты работы подтверждают возможность создания эффективных альтернатив проприетарным решениям NVIDIA с
сохранением функциональности и производительности.

