\section{Введение}

Графические процессоры общего назначения (GPGPU, англ. General-purpose graphics processing units) -- ускорители ...

Программные модели для гетерогенных вычислений, такие как CUDA (англ. Compute Unified Device Architecture)\cite{CUDA_Article} или OpenCL (англ. Open Computing Language), позволяют описывать поведение одного потока исполнения, который может быть мультиплицирован тысячи раз и запущен на наборе SIMD (англ. Single Instruction Multiple Data) вычислительных блоков. Нити исполнения объединяются в блоки (англ. thread block), которые затем формируют грид (англ. grid) \cite{CUDA_C_Programming_Guide}. 

Такой тип архитектуры, определяемый как SIMT (англ. Single Instruction Multiple Thread), позволяет GPU ускорителю вычислять результат инструкции одновременно для нескольких потоков, объединяя их в пачки, именуемые варпы (англ. warps, wavefronts). 





Каждый такт планировщик варпов (англ. warp scheduler) выбирает, какой из набора готовых к исполнению варпов, будет исполнен следующим. Выбор оптимальной стратегии планирования, в свою очередь, является краеугольным камнем разработки высокопроизводительного GPGPU вычислителя.

Конечная цель планировщика варпов - минимизация времени исполнения кода. 
