\section{Введение}

Задача планирования потоков является краеугольным камнем разработки любой высокопроизводительной массивно-параллельной системы. Лишь грамотное управление огромным количеством нитей исполнения позволяет полноценно утилизировать ресурсы вычислителя.  

Графический процессор общего назначения (GPGP, англ. General-purpose graphics processor) --- уникальный представитель такого рода массивно-параллельных систем. Изначально заточенные для отрисовки графики, графические процессоры позволяют получить колоссальный прирост производительности в задачах машинного обучения, компьютерного зрения, постквантовой криптографии и пр.    

Программные модели, такие как CUDA\cite{CUDA_Article} или OpenCL\cite{OpenCL}, позволяют описывать поведение одного потока исполнения и конфигурацию всей вычислительной сети. Заданным таким образом поток впоследствии будет мультиплицирован тысячи раз и запущен на наборе SIMD (англ. Single Instruction Multiple Data) вычислительных блоков. Такой тип архитектуры, определяемый как SIMT (англ. Single Instruction Multiple Thread)\cite{SIMT}, позволяет графическому процессору вычислять результат инструкции одновременно для нескольких потоков. 



Разработка системы планирования такого уровня сложности представляет собой нетривиальную инженерную и исследовательскую задачу. Все существующие системы являются проприетарными и попадают под категорию ноу-хау. 

, объединяя их в пачки, именуемые варпы (англ. warps, wavefronts). 



Задача от программной модели 

Нити исполнения объединяются в блоки (англ. thread block), которые затем формируют грид (англ. grid) \cite{CUDA_C_Programming_Guide}. 



Каждый такт планировщик варпов (англ. warp scheduler) выбирает, какой из набора готовых к исполнению варпов, будет исполнен следующим. Выбор оптимальной стратегии планирования, в свою очередь, является краеугольным камнем разработки высокопроизводительного GPGPU вычислителя.

Конечная цель планировщика варпов - минимизация времени исполнения кода. 

\subsection{Архитектура SIMT}

Программные модели для гетерогенных вычислений, такие как CUDA (англ. Compute Unified Device Architecture)\cite{CUDA_Article} или OpenCL (англ. Open Computing Language), позволяют описывать поведение одного потока исполнения, который может быть мультиплицирован тысячи раз и запущен на наборе SIMD (англ. Single Instruction Multiple Data) вычислительных блоков. Такой тип архитектуры, определяемый как SIMT (англ. Single Instruction Multiple Thread), позволяет GPU ускорителю вычислять результат инструкции одновременно для нескольких потоков, объединяя их в пачки, именуемые варпы (англ. warps, wavefronts). 
